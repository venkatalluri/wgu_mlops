{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bff130cd",
   "metadata": {},
   "source": [
    "Databricks notebook source\n",
    "============================================================\n",
    "JOB 2: INFERENCE NOTEBOOK\n",
    "- Loads registered model from MLflow Model Registry\n",
    "- Loads input data (could be from CSV, DBFS, or sklearn dataset)\n",
    "- Runs inference\n",
    "- Saves results with timestamp\n",
    "============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebef923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from mlflow import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51136c8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d865e77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 1 Load data for inference\n",
    "# ------------------------------------------------------------\n",
    "iris = load_iris(as_frame=True)\n",
    "df = iris.frame.copy()\n",
    "df.columns = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c550d158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create engineered features (same as in training)\n",
    "df[\"petal_area\"] = df[\"petal_length\"] * df[\"petal_width\"]\n",
    "df[\"sepal_area\"] = df[\"sepal_length\"] * df[\"sepal_width\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d0c309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop target to simulate unlabeled data\n",
    "X_new = df.drop(columns=[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6370695",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X_new.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef56739",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "# ------------------------------------------------------------\n",
    "# 2️⃣ Load model by alias\n",
    "# ------------------------------------------------------------\n",
    "CATALOG = \"main\"\n",
    "SCHEMA = \"default\"\n",
    "MODEL_NAME = \"IrisClassifier\"\n",
    "ALIAS = \"production\"\n",
    "client = MlflowClient()\n",
    "# Get information about the model\n",
    "model_info = client.get_model_version_by_alias(MODEL_NAME, ALIAS)\n",
    "model_tags = model_info.tags\n",
    "print(model_tags)\n",
    "# model_uri = f\"models:/{CATALOG}/{SCHEMA}/{MODEL_NAME}@{ALIAS}\"\n",
    "model_uri = f\"models:/{MODEL_NAME}@{ALIAS}\"\n",
    "#model = mlflow.pyfunc.load_model(model_uri)\n",
    "model = mlflow.sklearn.load_model(model_uri)\n",
    "print(f\"✅ Loaded model from MLflow registry: {model_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272ccbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"✅ Loaded model '{MODEL_NAME}' from MLflow registry.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0042191d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "# ------------------------------------------------------------\n",
    "# 3️⃣ Perform inference\n",
    "# ------------------------------------------------------------\n",
    "preds = model.predict(X_new)\n",
    "results_df = X_new.copy()\n",
    "results_df[\"prediction\"] = preds\n",
    "results_df[\"inference_timestamp\"] = datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1e81b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(results_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee137870",
   "metadata": {},
   "source": [
    "COMMAND ----------\n",
    "------------------------------------------------------------\n",
    "4️⃣ Save inference results\n",
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b3d598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Save to DBFS CSV\n",
    "output_path = f\"/dbfs/tmp/inference_results_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "results_df.to_csv(output_path, index=False)\n",
    "print(f\"✅ Inference results saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2de730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2 (optional): Save to Delta table for history\n",
    "spark_df = spark.createDataFrame(results_df)\n",
    "spark_df.write.mode(\"append\").format(\"delta\").saveAsTable(\"mlops_inference_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbf9d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"✅ Inference results appended to Delta table: mlops_inference_results\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
