{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "930aa9a1",
   "metadata": {},
   "source": [
    "Databricks notebook source\n",
    "============================================================\n",
    "JOB 2: INFERENCE NOTEBOOK\n",
    "- Loads registered model from MLflow Model Registry\n",
    "- Loads input data (could be from CSV, DBFS, or sklearn dataset)\n",
    "- Runs inference\n",
    "- Saves results with timestamp\n",
    "============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a65de4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from datetime import datetime, timezone\n",
    "from pyspark.sql import SparkSession\n",
    "from mlflow import MlflowClient\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bec4f8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "datetime.now(timezone.utc)\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a62bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 1 Load data for inference\n",
    "# ------------------------------------------------------------\n",
    "iris = load_iris(as_frame=True)\n",
    "df = iris.frame.copy()\n",
    "df.columns = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d53e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create engineered features (same as in training)\n",
    "df[\"petal_area\"] = df[\"petal_length\"] * df[\"petal_width\"]\n",
    "df[\"sepal_area\"] = df[\"sepal_length\"] * df[\"sepal_width\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f761e27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop target to simulate unlabeled data\n",
    "X_new = df.drop(columns=[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed651ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X_new.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2f902c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "# ------------------------------------------------------------\n",
    "# 2️⃣ Load model by alias\n",
    "# ------------------------------------------------------------\n",
    "CATALOG = \"main\"\n",
    "SCHEMA = \"default\"\n",
    "MODEL_NAME = \"IrisClassifier\"\n",
    "ALIAS = \"production\"\n",
    "client = MlflowClient()\n",
    "# Get information about the model\n",
    "model_info = client.get_model_version_by_alias(MODEL_NAME, ALIAS)\n",
    "model_tags = model_info.tags\n",
    "print(model_tags)\n",
    "# model_uri = f\"models:/{CATALOG}/{SCHEMA}/{MODEL_NAME}@{ALIAS}\"\n",
    "model_uri = f\"models:/{MODEL_NAME}@{ALIAS}\"\n",
    "#model = mlflow.pyfunc.load_model(model_uri)\n",
    "model = mlflow.sklearn.load_model(model_uri)\n",
    "print(f\"✅ Loaded model from MLflow registry: {model_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bbc34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"✅ Loaded model '{MODEL_NAME}' from MLflow registry.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d7da17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "# ------------------------------------------------------------\n",
    "# 3️⃣ Perform inference\n",
    "# ------------------------------------------------------------\n",
    "preds = model.predict(X_new)\n",
    "results_df = X_new.copy()\n",
    "results_df[\"prediction\"] = preds\n",
    "results_df[\"inference_timestamp\"] = datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4988ad2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(results_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4c77cd",
   "metadata": {},
   "source": [
    "COMMAND ----------\n",
    "------------------------------------------------------------\n",
    "4️⃣ Save inference results\n",
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42019f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Save to Local CSV\n",
    "timestamp = datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')\n",
    "output_dir = f\"/Workspace/Users/alluri.venkat1988@gmail.com/inference_results\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = f\"{output_dir}/inference_results_{timestamp}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f7e45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(output_path, index=False)\n",
    "print(f\"✅ Inference results saved to workspace path: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba05c1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2 (optional): Save to Delta table for history\n",
    "results_df[\"inference_timestamp\"] = datetime.now(timezone.utc).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "spark_df = spark.createDataFrame(results_df)\n",
    "spark_df.write.mode(\"append\").format(\"delta\").saveAsTable(\"mlops_inference_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aed0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"✅ Inference results appended to Delta table: mlops_inference_results\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
